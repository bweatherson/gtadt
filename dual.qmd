# Dual Mandate {#sec-dual}

## Introduction {#sec-dual-introduction}

This chapter marks a turning point in the book. From here on, a large amount of the time will be spent discussion situations involving dynamic choice. A central argument for GDT is that only it, or something like it, is compatible with plausible principles of dynamic choice. I'll call the dynamic choice situations I'll be interested in decision trees. To define them, it helps to start with an orthodox definition of a game tree.

> A finite extensive form (or frame) with perfect recall consists of the following items.    
> - A finite rooted directed tree.^[This is defined earlier, on page 75, but the details aren't important to what we're doing.]
> - A set of players _I_ = {1,...,n} and a function that assigns one player to every
decision node.
> A set of actions _A_ and a function that assigns one action to every directed edge, satisfying the restriction that no two edges out of the same node are assigned the same action.
> A set of outcomes_O_ and a function that assigns an outcome to every terminal node.
> For every player _i_ $\in$ _I_, a partition $\mathfrak{D}_i$ of the set _D~i~_ of decision nodes assigned to player _i_ (thus $\mathfrak{D}_i$ is a collection of mutually disjoint subsets of _D~i~_ whose union is equal to _D~i~_). Each element of Di is called an information set of player _i_. [@Bonanno2018, 119]

The quote continues with some restrictions on $\mathfrak{D}_i$, but I want to pause first to say what this is supposed to represent, and then it is easy to say informally what the constraints are. This partition is an epistemic accessibility relation. If two nodes are in the same cell of the partition, then when the player is in one of them, for all they know, they are in the other. The strongest thing they know, when they are at a particular node, is that they are somewhere in that cell of the partition.

Implicitly, the assumption here is that the right accessibility relation for epistemic logic is an equivalence relation. That's absurd in full generality. But I think in this context it's a harmless enough idealisation. That is, it's harmless enough if we remember that an idealisation here is a simplification, and not something that we think is desirable, or in any way something to aim for.

There are two standard restrictions on $\mathfrak{D}_i$. First, players know what moves are possible, so for any two nodes in a cell of $\mathfrak{D}_i$, the same actions are possible. Second, players remember their actions, so for any two nodes in a cell of $\mathfrak{D}_i$, the paths to those nodes only differ with respect to moves made by other players.

We're also going to make three more assumptions that are I think implicit in the standard formulation, but not always made explicit.^[Bonanno does make all these explicit at various times, but doesn't list them in one spot for neat quoting.] Say a 'play' is a particular path through the tree that happens in real time. The assumptions concern what happens in all plays of a tree thus understood.

First, each player is motivated to get the best outcome possible. If we interpret the outcomes as preferences of the player at the end of the play, and assume that players are motivated by their current preferences, this is in effect an assumption that preferences do not change over the course of the play.

Second, the tree is common knowledge at the start of the play. A player will not acquire new capacities over the game, or learn that they had capacities they didn't realise. They will not acquire any capacity to make distinctions between possibilities that they did not have at the start of the play. So, for instance, there can't be a point in the tree where a player meets a new individual, and acquires by acquaintance the ability to have singular thoughts about that person, and distinguish that person from descriptive duplicates.[^dual-1]

Third, it is common knowledge among all the time-slices of a player that all of the player's time-slices are rational. At this stage, it's important that 'rational' be left as something of a placeholder, or, perhaps better, a variable. In some sense the aim of the theorising around here is to solve for the value of 'rational' given some intuitive data about rational play. But whatever rationality is, we assume the player always has it, they always know they will always have it, they always know that they always know they will always have it, and so on.

[^dual-1]: Following @Stalnaker2008, I think this constraint means that we can't represent the Sleeping Beauty problem as a tree, since there Beauty gains the capacity to have singular thoughts about a time, the 'now' when she awakes, that she did not previously have.

A _strategy_ for player _i_ is a function from the members of $\mathfrak{D}_i$ to probability distributions over actions. That is, the strategy says which action, or mixed action, a player will do at each information set that they could reach consistent with the rules of the game. 

It will become important that these are extremely fine-grained. A strategy describes what a player will do at nodes that are ruled out by other choices the player makes. Consider a game that consists of two rounds of some simple two-player, two-choice game, like Prisoners' Dilemma, with the results of the first round revealed before the second round is played. Each player has 32 strategies. (So there are 1024 strategy pairs.) The tree for the game has five information sets where each player might move; the first-round game, then, since there are four ways the first game could go, four more possibilities for what they might know when the second-round game is played. Since there are 2~5~, i.e., 32, ways to make binary choices over five possible choices, there are 32 strategies.^[Some of the results of the next few chapters came from work I started investigating what happened in two-round decision problems like that. None of that work appears here, because for every result I found, I eventually found an illustration with many fewer strategies. If you're grateful you don't have to look at 32-by-32 strategy tables, you can't imagine how grateful I am to not be writing them.]

I'm going to assume a kind of realism about strategies. Players actually have dispositions about what they will do at nodes that aren't reached, and even at nodes that couldn't be reached given their prior dispositions. These dispositions are at least real enough to play the following two roles: they can be the conditions that conditional probabilities are defined over, and they are subject to evaluation as rational or irrational.

Trees in game theory textbooks frequently designate one special player: Nature [@Bonanno2018, 134ff]. Nature is different in a few respects. It does not have any special outcome; the outcomes are utilities for the players other than Nature. It is usually taken to be common knowledge among the other players that they are rational; but Nature is not rational. Rather, at every node where Nature makes a move, there is an externally provided probability distribution over the possible moves. These probabilities are common knowledge at the start of the game.^[Though note that does not mean all players know the probability of each move at any time Nature moves. It could be that while the game is going, a player does not know precisely which node they are at, so they do not know what probability distribution Nature is using. This is common in card games. If I don't know what's in your hand, I don't know what cards are left, so I don't know whether the probability that Nature is about to give a player the Jack of Hearts is, say, 0.025, or 0.]

A decision tree is like a game tree, but with more players that are distinctive in the way Nature is. There is only one player stipulated to be rational: Chooser. (They will be player 1 in what follows, unless stated otherwise.) At most one player is Nature, in the sense of the previous paragraph. The other players are all demons. If a demon moves at a node, then Chooser knows not the unconditional probability of that demon's possible actions, but the conditional probability of the demon's actions given their strategy choice. In more familiar terms, the demon predicts their strategy with a certain probability of accuracy, and has dispositions about what to do given each prediction.

While these demons are a lot like the demons that have been central to decision theory ever since the introduction of Newcomb's Problem, there are two things I'm doing differently here that I want to note up front. First, there may be more than one demon. In the examples to follow, there will occasionally be four players: Chooser, two demons, and Nature. Second, the conditional probabilities are conditional on strategies, not just choices. This will matter in two stage games; to make the second stage game be just like the familiar games in decision theory (like Newcomb's Problem), it will be important that Demon's dispositions are sensitive to Chooser's dispositions about the second game. And this is important even in cases (of which there will be a few below) where Chooser can choose whether to play that second-round game.

## Two Familiar Approaches to Decision Trees


The elements of Di satisfy the following restrictions:


 where something is a game tree if and only if the following conditions are met.

-   At every step, Chooser either receives some information, or makes a choice.
-   Chooser knows before the first step what possible choices will be available at each step, given the prior steps, or what possible pieces of information could be received.
-   No matter what happens, the tree ends after finitely many steps. (Though it may end after more or fewer steps depending on what happens).
-   Chooser knows before the first step what payout they will receive given each possible sequence of choices and information.
-   Before the first step, chooser has a probability for each possible piece of information they could receive, given the prior steps in the tree.

- Dynamic turn, which lasts the rest of the way
- What a dynamic decision problem is, and what it isn't
- Define strategy, note that it includes realism about dispositions
- Two options: Purely strategic, and purely consequentialist
- My view: Neither; the strategy implemented and the choices made are both rationally defensible

## Philosophical Background

- Dr Strangelove and the purely strategic
- Zaphod Beeblebrox and the purely consequentialist
- Stalnaker on future
- Spencer on binding; as it stands not a great argument, maybe humans can't bind but ideal humans should. But it seems, and this is a judgment call, that we don't get any extra explanatory power from doing that. Maybe we do, but most people will give up on plans that they are sure have failed, if the stakes are high enough.
- My picture; can make plans and carry them out, conditional on the plans being rational were they to be reconsidered.
- This is not a trivial constraint; it doesn't just say bind yourself to what you'd do anyway. It says that even if multiple options are permissible, can bind yourself to one of them.

## Against Pure Strategy

We have to do this in parts.

### Against Pure Strategy and EDT

Cut and paste from existing discussion

### Against Pure Strategy and CDT

Have some of this already
Note that there are complications
Some of the argument here is not the cases, which don't seal the case, but the philosophical considerations from background

## Against Pure Consequentialism

### Two Examples

Note the Spencer example, but don't go over it; relies on unavailability of mixed strategy
Objection to the regret based strategies; 0, 5 // 2, 2; alternative is to get 1.
Objection to GDT; 1, 0 // 0, 5; alternative is to get 2.

### Analysis of the Examples

Intuitively, could do better.
Do the choosers have a defence?
There certainly are cases where we rationally play a sub-optimal strategy: will cease being rational and/or will change preferences
It feels to me that that's all; otherwise it's unacceptable alienation. Chooser endorses the choices being made, but regrets them. That doesn't make sense.
And this does feel like an acceptable form of binding
People can, after all, make plans, and we can plan around them.

## Mixtures

- Dual Mandate requires mixtures
- Can see this with an example that Spencer uses
- I think since the dual mandate is independently plausible, this is an argument that ideal agents can mix.
- Of course, the dual mandate is absurd for non-ideal agents; see the eternal debate between actualists and eternalists