# Causal {#sec-causal}

It shouldn't be controversial\[\^causal-1\] to claim that game theory textbooks are committed a broadly causal version of decision theory.[^causal-1] For one thing, they always recommend defecting in Prisoners' Dilemma, even when playing with a twin. As David Lewis showed, this is equivalent to recommending two-boxing in Newcomb's Problem [@Lewis1979e]. They endorse the causal decision theorist's signature argument form: the deletion of strongly dominated strategies. Indeed, the typical book introduces this before it introduces anything about probability. When they do get around to probabilities, they tend to define the expected value of a choice in a way only a causal decision theorist could endorse. In particular, they define expected values using unconditional, rather than conditional, probabilities.[^causal-2] And the probabilities are simply probabilities of states, not probabilities of any kind of counterfactual. Indeed, you can go entire textbooks without even getting a symbol for a counterfactual conditional.

[^causal-1]: This point is made by @Harper1988, and many (though not all) of the conclusions I draw in this paper will be similar to ones he drew.

[^causal-2]: See, for instance, the introduction of them on page 136 of @Bonanno2018. And note that we get 135 pages before the notion of an expectation is introduced; that's how much is done simply with dominance reasoning

What's more controversial is that they are right to adopt a kind of causal decision theory (CDT).[^causal-3] In the recent literature, I think there are three main kinds of problem that have been raised for CDT. First, it does badly in cases where there are no pure ratifiable strategies. Second, it gives strange results in cases involving betting on grand propositions about the past history of the world, or about the laws of nature. Third, it leaves its proponents will less money in Newcomb's Problem than EDT does. In this chapter I'll respond to each of these in turn.

[^causal-3]: Recall that I'm using 'CDT' here as the name for a family of theories. The point of this chapter will be to argue that the member of the family I prefer is immune to several challenges that have been raised against other members of the family.

## No Ratifiable Choices {#sec-no-ratify}

In some simple cases, neither of the options on the table look very good by the lights of GDT. @tbl-no-ratify-1 is an almost maximally simple case.

|       | **PA** | **PB** |
|:-----:|:------:|:------:|
| **A** |   0    |  100   |
| **B** |  100   |   0    |

: A problem with no ratifiable choice {#tbl-no-ratify-1}

Everyone agrees that there is nothing to choose between the options here.[^causal-4] Things get complicated when A gets somewhat sweetened, say by adding 99 to the payouts if Chooser selects A, resulting in @tbl-no-ratify-2.

[^causal-4]: Almost everyone agrees that Chooser should be indifferent between A and B here. I don't, for reasons that will become important presently, and will be discussed much more in @sec-indecisive. I think A and B should be treated symmetrically, of course, but they are incomparable not equally good.

|       | **PA** | **PB** |
|:-----:|:------:|:------:|
| **A** |   99   |  199   |
| **B** |  100   |   0    |

: An asymmetric problem with no ratifiable choice {#tbl-no-ratify-2}

Many versions of CDT, including GDT, do not unconditionally recommend A in this case. Yet there are many problems with the same structure as @tbl-no-ratify-2 where people have insisted that intuition says A is the only rational choice, and it is a problem for a decision theory that doesn't agree.[^causal-5]

[^causal-5]: This objection goes back to @Richter1984. The most memorable version of an asymmetric problem with no ratifiable choice is the Psychopath Button case presented by Andy @Egan2007.

A related objection is raised by Arif @Ahmed2014a and by Jack Spencer and Ian Wells [-@SpencerWells2019]. I'll focus on the latter version, but the points are essentially the same. Start with @tbl-no-ratify-1 and add a third option X. X gets a guaranteed return of 40, and if Demon predicts X, then A and B return 50. They call this problem [The Frustrator](#tbl-frustrator).

|       | **PA** | **PB** | **PX** |
|:-----:|:------:|:------:|:------:|
| **A** |   0    |  100   |   50   |
| **B** |  100   |   0    |   50   |
| **X** |   40   |   40   |   40   |

: The Frustrator {#tbl-frustrator}

They say, and many seem to agree, that intuition says that taking X is the only rational option. This is a bit surprising since there are two things wrong with X. Or, better, there is one thing wrong with X that has two manifestations which turn out to be equivalent.

For one thing X is strongly dominated by the mixed strategy of playing A and B with probability 0.5 each. Whatever Demon does, that mixed strategy has an expected return of 50, while X has a guaranteed return of 40.

For another thing, there is no probability distribution over the three states, PA, PB, and PX, such that X maximises expected utility. If Pr(PA) ≥ Pr(PB), then A will have a higher expected return than X, and if Pr(PB) ≥ Pr(PA), then B will have a greater return than X. In game-theoretic terms, X is not a best response [@Bonanno2018, 41]; no matter what Chooser thinks Demon will do, indeed no matter what probability Chooser has over Demon's choices, X is sub-optimal.

The last two things turn out to be equivalent. As @Pearce1984 shows, an option is sometimes a best response iff it is not strictly dominated by any other pure or mixed strategy.[^causal-6] That is, for any option O, there is some probability distribution over the states such that no alternative to O has a higher expected utility iff there is no mixture of alternatives to O that has a higher expected return than O in all states.

[^causal-6]: Bonanno [-@Bonanno2018, 207] attributes this to Pearce, who has a rather elegant proof of the result that involves turning the decision problem into a zero-sum game, and applying a famous result of Nash's.

GDT's response to these kinds of problems is in two parts. One part is to argue, as I will in @sec-indecisive, that the intuitions behind cases like this are unstable. The other is to argue that in fact the right choice here is to play the mixed strategy. That requires arguing that mixed strategies are available, as I will in @sec-mixed, and indeed saying more about what it is to play a mixed strategy. And then it requires appealing to Pearce's result to say that any option ruled out in cases like [The Frustrator](#tbl-frustrator) is in fact strictly dominated, and so not choice-worthy.

There are a lot of promissory notes in the last paragraph, but hopefully I've said enough to say how GDT will, eventually, respond to cases like these.

## Laws, and other Non-Events

-   Cite Ahmed book for the general problem
-   Cite Hedden's recent version
-   Note I'm really dismissing this problem not replying to it
-   Objection 1: This violates the idealising constraints; we don't know what we can do.
-   Objection 2: These are not events, and causal independence requires independent events. (Caveat: All that matters is that it can be treated as an event, as in Spence or ChoKreps. Can it? Eh, maybe.)
-   Objection 3: I think we do maybe cause the laws (or the past). One reason - Humeanism implies future events are partially constitutive of the laws. (Caveat: My response to Hawthorne.) And if determinism is true, then counterfactuals go all funny; maybe the past is counterfactually sensitive to current actions (for yes, see Lewis; for no, see Dorr).
-   General objection: The point is to explain, predict, and maybe evaluate, ordinary people making ordinary decisions. And ordinary people come with ordinary pictures of how the world works. If it turned out the theory didn't even apply to people with non-standard notions of causation, or who applied the notion of causation beyond its intended scope of understanding current day interactions between medium sized dry goods, I wouldn't be too worried.

## War on WAR {#sec-war-on-war}

That leaves the point that CDT leaves one poorly off in Newcomb's Problem, while other theories, like evidential decision theory (EDT) leave one well off. This isn't a particular mark against CDT, since other theories, like EDT, leave one poorly off in some situations. Here is one such case.

There are two demons, who will predict what Chooser will do. Both of them are arbitrarily good, though not quite perfect, and their errors are independent. Both demons will predict what Chooser does before anything else happens. Chooser will play either the left or right game in @tbl-edt-war.

::: {#tbl-edt-war layout-ncol="2"}
|       | **PA** | **PB** |
|:-----:|:------:|:------:|
| **A** |   2    |   0    |
| **B** |   3    |   1    |

: Demon-1 predicts A {#tbl-war-left}

|       | **PA** | **PB** |
|:-----:|:------:|:------:|
| **A** |  1002  |  1000  |
| **B** |  1003  |  1001  |

: Demon-1 predicts B {#tbl-war-right}

A Newcomb problem with two demons.
:::

If Demon-1 predicts that Chooser will play A, Demon-1 will offer Chooser @tbl-war-left; if Demon-1 predicts that Chooser will play B, Demon-1 will offer Chooser @tbl-war-right. And Chooser knows what they are playing, that's part of what it is to play a game, so Demon-1's prediction will be announced, though Demon-2's prediction will be secret. After Chooser makes a decision, Demon-2's prediction will be used for determining whether the payout is from column PA or PB. In almost all cases, if Chooser uses CDT, they will get 1001, while if they use EDT, they will get 2. So in this case, CDT will get more than EDT.

This case is not meant as an objection to EDT. It is perfectly fair for the evidential decision theorist to complain that they have simply been the victim of a Demon who intends to punish users of EDT, and reward users of CDT. That seems a perfectly fair complaint. But if the evidential decision theorist makes it, they cannot object when causal decision theorists, such as @Lewis1981e, use the same language to describe Newcomb's Problem. The 'objection' that CDT leaves one poorly off in one particular case is equally an objection to everyone, and so it is an objection to no one.

One might object that this is unfair because at the time they make decisions, the EDTer and the CDTer have different evidence. After all, they will know what Demon-1 predicted and it will (almost certainly) be different in each case. Can we get rid of that step? We can, but it's a bit complicated, and I've put that case in @sec-war-signal. The short version is that there is an example where some versions of CDT predictably do better than EDT, even though at every point the followers of EDT and (those versions of) CDT have the same evidence when they are making choices.

While followers of EDT end up with more money than followers of causal theories *when playing Newcomb's Problem*, this is not because of the distinctive money-making powers of EDT. It's because Newcomb's Problem is designed to leave causally based decision theories badly off. Design a case to leave evidential theories badly off, and they'll be badly off. The "Why Ain'Cha Rich?" consideration tells against everyone, so it overgenerates, so it should be rejected.

Well, not quite everyone. It doesn't tell against some kind of 'resolute' decision theories which recommend one-box in Newcomb's Problem and Up in @tbl-edt-war.[^causal-7]. Those theories leave their proponents well off in all the cases. The so-called 'foundational decision theory' that @LevinsteinSoares2020 endorse also endorse the same three choices. But those theories are vulnerable to much more serious objections, that I'll come to in @sec-against-pure-strategy.

[^causal-7]: These theories recommend always playing Up in @fig-second-anti-war, the 'complicated' example I mentioned above

So I conclude that there is no good objection to adopting a broadly causal decision theory, much as the game theorists do. But which version of CDT do they adopt, and are they right to do so? That will take us much more time.
